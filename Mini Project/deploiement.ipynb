{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":48192,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":40313,"modelId":56480},{"sourceId":48205,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":40320,"modelId":56498},{"sourceId":48209,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":40324,"modelId":56502},{"sourceId":52110,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":43808,"modelId":60520},{"sourceId":52362,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44000,"modelId":60752},{"sourceId":52611,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44189,"modelId":61008}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T13:09:34.518545Z","iopub.execute_input":"2024-05-20T13:09:34.519197Z","iopub.status.idle":"2024-05-20T13:09:34.531846Z","shell.execute_reply.started":"2024-05-20T13:09:34.519163Z","shell.execute_reply":"2024-05-20T13:09:34.530839Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/captioning/tensorflow2/model/1/model (1).h5\n/kaggle/input/imgg/tensorflow1/model/1/model.h5\n/kaggle/input/nlp_img_cap/tensorflow2/imgcapmodel/1/model.h5\n/kaggle/input/unet/tensorflow2/unet_mn/1/unet_mn.h5\n/kaggle/input/fcn/tensorflow2/fcn/1/fcn_model.h5\n/kaggle/input/deep_lab/tensorflow2/deeplab/1/DeeplabV3_mobilenet.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install streamlit -q","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:34.533702Z","iopub.execute_input":"2024-05-20T13:09:34.533998Z","iopub.status.idle":"2024-05-20T13:09:46.917574Z","shell.execute_reply.started":"2024-05-20T13:09:34.533975Z","shell.execute_reply":"2024-05-20T13:09:46.916368Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade keras tensorflow\n\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\nfrom tensorflow.keras.initializers import Orthogonal\n\ncustom_objects = {'Orthogonal': Orthogonal}\n\n# Load your trained model\nmodel = tf.keras.models.load_model(\"/kaggle/input/captioning/tensorflow2/model/1/model (1).h5\", custom_objects=custom_objects)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:11:01.277193Z","iopub.execute_input":"2024-05-20T13:11:01.277895Z","iopub.status.idle":"2024-05-20T13:12:04.536083Z","shell.execute_reply.started":"2024-05-20T13:11:01.277863Z","shell.execute_reply":"2024-05-20T13:12:04.534919Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.summary","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.184716Z","iopub.status.idle":"2024-05-20T13:09:47.185068Z","shell.execute_reply.started":"2024-05-20T13:09:47.184890Z","shell.execute_reply":"2024-05-20T13:09:47.184904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download ngrok\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n\n# Unzip the downloaded file\n!unzip ngrok-stable-linux-amd64.zip","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.186133Z","iopub.status.idle":"2024-05-20T13:09:47.186497Z","shell.execute_reply.started":"2024-05-20T13:09:47.186292Z","shell.execute_reply":"2024-05-20T13:09:47.186307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!chmod +x ngrok","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.188306Z","iopub.status.idle":"2024-05-20T13:09:47.188784Z","shell.execute_reply.started":"2024-05-20T13:09:47.188544Z","shell.execute_reply":"2024-05-20T13:09:47.188575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!./ngrok authtokens 2gTgesqVJ5fXr6FiY4N7R46L7hs_5FKChinrwKGCVpZw34uEA","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.190854Z","iopub.status.idle":"2024-05-20T13:09:47.191339Z","shell.execute_reply.started":"2024-05-20T13:09:47.191106Z","shell.execute_reply":"2024-05-20T13:09:47.191124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nst.title('Image Captioning App')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.192371Z","iopub.status.idle":"2024-05-20T13:09:47.192829Z","shell.execute_reply.started":"2024-05-20T13:09:47.192605Z","shell.execute_reply":"2024-05-20T13:09:47.192624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import streamlit as st\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.densenet import preprocess_input\nimport pickle\n\n# Load your trained captioning model\ncaption_model = load_model('path_to_your_caption_model.h5')\n\n# Load the tokenizer\nwith open('tokenizer.pkl', 'rb') as handle:\n    tokenizer = pickle.load(handle)\n\n# Define maximum length of captions\nmax_length = 34  # Change this based on your model\n\n# Load your word2idx and idx2word dictionaries\nwith open('word2idx.pkl', 'rb') as handle:\n    word2idx = pickle.load(handle)\n\nwith open('idx2word.pkl', 'rb') as handle:\n    idx2word = pickle.load(handle)\n\n# Define the DenseNet201 model for feature extraction\nimg_size = 224\nbase_model = DenseNet201(weights='imagenet', include_top=False, pooling='avg')\nfe = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n\ndef predict_caption(model, feature, tokenizer, max_length, word2idx, idx2word):\n    in_text = 'startseq'\n    for _ in range(max_length):\n        sequence = tokenizer.texts_to_sequences([in_text])[0]\n        sequence = pad_sequences([sequence], maxlen=max_length, padding='post')\n        y_pred = model.predict([np.array([feature]), np.array(sequence)])\n        y_pred = np.argmax(y_pred)\n        word = idx2word.get(y_pred)\n        if word is None:\n            break\n        in_text += ' ' + word\n        if word == 'endseq':\n            break\n    return ' '.join(in_text.split()[1:-1])\n\n# Streamlit app\nst.title('Image Captioning App')\n\nuploaded_file = st.file_uploader('Choose an image...', type='jpg')\n\nif uploaded_file is not None:\n    # Load and preprocess the image\n    img = load_img(uploaded_file, target_size=(img_size, img_size))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n\n    # Extract features using DenseNet201\n    feature = fe.predict(img, verbose=0)\n    \n    # Generate the caption\n    caption = predict_caption(caption_model, feature, tokenizer, max_length, word2idx, idx2word)\n    \n    # Display the image and the caption\n    st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)\n    st.write('Generated Caption: ', caption)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.194460Z","iopub.status.idle":"2024-05-20T13:09:47.194907Z","shell.execute_reply.started":"2024-05-20T13:09:47.194676Z","shell.execute_reply":"2024-05-20T13:09:47.194695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!npm install localtunnel","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.196144Z","iopub.status.idle":"2024-05-20T13:09:47.196667Z","shell.execute_reply.started":"2024-05-20T13:09:47.196378Z","shell.execute_reply":"2024-05-20T13:09:47.196399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!streamlit run app.py & npx localtunnel --port 8501","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:09:47.197975Z","iopub.status.idle":"2024-05-20T13:09:47.198402Z","shell.execute_reply.started":"2024-05-20T13:09:47.198181Z","shell.execute_reply":"2024-05-20T13:09:47.198200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}